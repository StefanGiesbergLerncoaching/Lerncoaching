# ğŸ‘ï¸ Eye-Tracking Lese-Diagnostik v2.0

**Browser-basiertes Eye-Tracking-System zur Diagnose von Lesetaktiken bei hochbegabten Kindern mit Lese-Rechtschreib-SchwÃ¤che**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![WebGazer.js](https://img.shields.io/badge/WebGazer.js-v3.0-green.svg)](https://webgazer.cs.brown.edu/)

---

## ğŸ¯ Projektziel

Entwicklung eines **objektiven, web-basierten Diagnose-Tools**, das verschiedene Lesetaktiken bei hochbegabten Kindern identifiziert:

- **Dekodierer:** Langsames, buchstabenweises Lesen
- **Rater:** Schnelles Ãœberfliegen/Raten basierend auf Wortformen
- **Kompensatoren:** Hoher kognitiver Aufwand durch stÃ¤ndige RÃ¼cksprÃ¼nge und Korrekturen

Das System ermÃ¶glicht:
1. **Interventions-Dokumentation** (Vorher-Nachher-Vergleiche)
2. **Taxonomie von Lesetaktiken** (automatische Klassifikation)
3. **Wissenschaftliche Verwertung** (Paper-Publikation, Trainingskonzept)

---

## âœ¨ Features

### **Multi-Line-Tracking v2.0:**
- âœ… **Zeile 1:** OberlÃ¤ngen/UnterlÃ¤ngen-Analyse (Vertikal-Tracking)
- âœ… **Zeile 2:** Silben-Sequenz-Analyse (Horizontal-Tracking)
- âœ… **Zeile 3:** Standard-Wort-Tracking (4-Regionen pro Wort)

### **Automatische Analyse:**
- âœ… Python-Script mit **5 Visualisierungen** (PNG)
- âœ… **Automatische Klassifikation** (Dekodierer/Rater/Kompensator)
- âœ… **Detaillierter Report** mit diagnostischen Empfehlungen

### **Technologie:**
- âœ… **WebGazer.js** - Webcam-basiertes Eye-Tracking (keine Hardware nÃ¶tig!)
- âœ… **Responsive Design** - Funktioniert auf 768px - 1200px+ Bildschirmen
- âœ… **CSV-Export** - 3 separate Dateien mit 227+ Datenpunkten

---

## ğŸš€ Quick Start

### **1. Repository klonen:**
```bash
git clone https://github.com/[YOUR-USERNAME]/eye-tracking-diagnostik.git
cd eye-tracking-diagnostik
```

### **2. Dependencies installieren:**
```bash
pip install pandas numpy matplotlib seaborn --break-system-packages
```

### **3. Test im Browser starten:**
```bash
# VS Code mit Live Server Extension:
# Rechtsklick auf index.html â†’ "Open with Live Server"

# Oder mit Python:
python -m http.server 8000
# Dann Ã¶ffnen: http://localhost:8000
```

### **4. Test durchfÃ¼hren:**
1. Browser Ã¶ffnet Willkommens-Screen
2. "Starten" klicken â†’ Webcam erlauben
3. **9-Punkte-Kalibrierung** (jeden Punkt 3Ã— anklicken)
4. Text **langsam laut vorlesen**
5. "Fertig" klicken â†’ 3 CSV-Dateien werden heruntergeladen

### **5. Daten analysieren:**
```bash
python analysis/analyze_eyetracking.py \
  line1_vertical_123.csv \
  line2_syllables_123.csv \
  line3_words_123.csv

# Output: output_analysis/ Ordner mit 5 PNGs + 1 Report
```

**Detaillierte Anleitung:** Siehe [`SETUP.md`](SETUP.md)

---

## ğŸ“Š Beispiel-Output

### **Automatische Klassifikation:**
```
Profil: DEKODIERER
Konfidenz: 75.3%
BegrÃ¼ndung: Langsames, grÃ¼ndliches Dekodieren (jeder Buchstabe wird gelesen)

Scores:
  - Decoder: 9
  - Guesser: 3
  - Compensator: 0
```

### **Visualisierungen:**
- `line1_vertical_distribution.png` - OberlÃ¤ngen vs. UnterlÃ¤ngen
- `line2_syllable_sequence.png` - Silben-Lesereihenfolge
- `line3_regions_heatmap.png` - 4-Regionen-Heatmap
- `profile_radar.png` - Leserprofil-Radar-Chart
- `statistics_summary.png` - Statistik-Ãœbersicht

---

## ğŸ“ Projektstruktur

```
eye-tracking-diagnostik/
â”œâ”€â”€ index.html                  # Haupt-Interface (v2.0)
â”œâ”€â”€ js/
â”‚   â””â”€â”€ aoi-tracker-v2.js       # Multi-Line-Tracking-Engine
â”œâ”€â”€ stimuli/
â”‚   â””â”€â”€ baseline/
â”‚       â””â”€â”€ text_multiline.json # 3-Zeilen-Test-Text
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ analyze_eyetracking.py  # Python-Analyse-Script
â”‚   â””â”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ output_analysis/            # Auto-generiert
â”‚   â”œâ”€â”€ *.png                   # Visualisierungen
â”‚   â””â”€â”€ report_*.txt            # Diagnostischer Report
â””â”€â”€ docs/                       # VollstÃ¤ndige Dokumentation
    â”œâ”€â”€ Struktur_und_Stand_v2.md
    â”œâ”€â”€ Metriken_v2.md
    â””â”€â”€ IP_Schutz_und_Workflow.md
```

---

## ğŸ”¬ Wissenschaftlicher Hintergrund

### **Theoretische Basis:**
- **Asynchrone Entwicklung** (Silverman, 1997)
- **Twice-Exceptional Profiles** (Kranz et al., 2024)
- **Eye-Movement Control in Reading** (Rayner, 1998)

### **Technologie:**
- **WebGazer.js** (Papoutsaki et al., 2016, Brown University)
  - Browser-basiertes Eye-Tracking via Webcam
  - ~50-100px Genauigkeit, 10-15 Hz Sampling-Rate

---

## ğŸ“ˆ Metriken

### **Zeile 1: Vertical Tracking**
- **10 Metriken pro Chunk:** FFD, TRT, Fixation Count, Revisits, Top/Bottom-Duration, Top-Ratio
- **Diagnostischer Fokus:** OberlÃ¤ngen-SensitivitÃ¤t

### **Zeile 2: Syllable Tracking**
- **8 Metriken pro Silbe:** FFD, Skip, Read-Order, Jump-Distance
- **Diagnostischer Fokus:** Sequenzielle vs. chaotische Lesereihenfolge

### **Zeile 3: Standard Word Tracking**
- **13 Metriken pro Wort:** FFD, TRT, 4Ã—Region-Duration, Left/Top-Ratio
- **Diagnostischer Fokus:** Horizontale/vertikale Fixations-Verteilung

**â†’ Total: 227+ Datenpunkte pro Test-Session**

Details: Siehe [`docs/Metriken_v2.md`](docs/Metriken_v2.md)

---

## ğŸ› ï¸ System-Anforderungen

### **Client-Seite:**
- **Browser:** Chrome/Edge (neueste Version empfohlen)
- **Webcam:** 720p+ (1080p ideal)
- **Bildschirm:** 1366Ã—768 Minimum, 1920Ã—1080 empfohlen
- **Internet:** Nur fÃ¼r WebGazer.js-CDN (einmalig beim Laden)

### **Analyse (optional):**
- **Python:** 3.8+
- **Dependencies:** pandas, numpy, matplotlib, seaborn

---

## ğŸ“ Verwendung fÃ¼r Forschung

### **Zitiervorschlag:**
```
Giesberg, S. (2026). Eye-Tracking Lese-Diagnostik v2.0: 
Browser-basiertes System zur Taxonomie von Lesetaktiken bei 
hochbegabten Kindern. GitHub Repository. 
https://github.com/[YOUR-USERNAME]/eye-tracking-diagnostik
```

### **Lizenz:**
MIT License - Siehe [LICENSE](LICENSE) fÃ¼r Details

### **Ethik:**
Dieses Tool ist fÃ¼r **Forschungs- und Diagnostik-Zwecke** gedacht. Bei Verwendung mit Kindern:
- âœ… Elterneinwilligung einholen
- âœ… Ethik-Kommission konsultieren (bei institutioneller Forschung)
- âœ… Datenschutz beachten (keine Webcam-Aufzeichnung!)

---

## ğŸš§ Roadmap

### **Phase 2: Intervention (In Arbeit)**
- [ ] Leetspeak-Generator (automatische Text-Konvertierung)
- [ ] OberlÃ¤ngen-Intervention (CSS-Maskierung)
- [ ] Timeline-Erweiterung (Baseline â†’ Intervention â†’ Retest)
- [ ] Delta-Metriken (Intervention vs. Baseline)

### **Phase 3: Validierung (Geplant)**
- [ ] Tests mit echten Probanden (n=20-30 Kinder)
- [ ] Inter-Rater-ReliabilitÃ¤t
- [ ] Vergleich mit etablierten Tests (SLRT-II, ELFE)
- [ ] Paper-Publikation (Dyslexia, Gifted Child Quarterly)

---

## ğŸ¤ Contributing

BeitrÃ¤ge sind willkommen! Bitte:
1. Fork das Repository
2. Erstelle einen Feature-Branch (`git checkout -b feature/AmazingFeature`)
3. Commit deine Ã„nderungen (`git commit -m 'Add some AmazingFeature'`)
4. Push zum Branch (`git push origin feature/AmazingFeature`)
5. Ã–ffne einen Pull Request

---

## ğŸ“§ Kontakt

**Projektentwickler:** Stefan Giesberg  
**Zweck:** Hochbegabten-Diagnostik & Lesetaktik-Taxonomie  
**Status:** MVP v2.0 funktionsfÃ¤hig (Januar 2026)

**GitHub Issues:** [https://github.com/[YOUR-USERNAME]/eye-tracking-diagnostik/issues](https://github.com/[YOUR-USERNAME]/eye-tracking-diagnostik/issues)

---

## ğŸ“š Weitere Dokumentation

- [SETUP.md](SETUP.md) - Lokale Einrichtung Schritt-fÃ¼r-Schritt
- [docs/Struktur_und_Stand_v2.md](docs/Struktur_und_Stand_v2.md) - VollstÃ¤ndige Projekt-Dokumentation
- [docs/Metriken_v2.md](docs/Metriken_v2.md) - Detaillierte Metrik-Beschreibungen
- [docs/IP_Schutz_und_Workflow.md](docs/IP_Schutz_und_Workflow.md) - Lizenzierung & Klienten-Workflow
- [CHANGELOG.md](CHANGELOG.md) - Version-History

---

## âš ï¸ Bekannte Limitationen

- **WebGazer-Ungenauigkeit:** ~50-100px, keine echte Saccade-Erkennung
- **Kalibrierungs-SensitivitÃ¤t:** Brille/Beleuchtung stark einflussreich
- **Speedreading-Problem:** Hohe Skip-Rates bei zu schnellem Lesen
  - **LÃ¶sung:** Instruktion betonen: "Langsam laut vorlesen!"

---

## ğŸ™ Acknowledgments

- **WebGazer.js** - Papoutsaki et al. (2016), Brown University
- **Matplotlib/Seaborn** - Python-Community
- **Anthropic Claude** - KI-assistierte Entwicklung

---

**â­ Star dieses Projekt, wenn es dir hilft!**

---

*Letztes Update: 16.02.2026 - v2.0*
